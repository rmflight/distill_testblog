[
  {
    "path": "posts/2013-09-17-r-rstudio-and-release-and-dev-bioconductor/",
    "title": "R, RStudio, and Release and Dev Bioconductor",
    "description": "Working with the development version of Bioconductor on linux can be a pain. This is one way to do it.",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2013-09-17",
    "categories": [
      "R",
      "bioconductor",
      "rstudio"
    ],
    "contents": "\nUpdate 2021-02-18: Now I would just use the r-docker image and the RStudio interface. I actually just did this recently to test updates to my package.\nI have one Bioconductor package that I am currently responsible for. Each bi-annual release of Bioconductor requires testing and squashing errors, warnings and bugs in a given package. Doing this means being able to work with multiple versions of R and multiple versions of Bioconductor libraries on a single system (assuming that you do production work and development on the same machine, right?).\nI really, really like RStudio as my working R environment, as some of you have read before. So how do we get RStudio on our Linux system to respect which version of R and libraries we want to use?\nSetup\nThis assumes that you have your R installs set somewhere properly, and a normal library for production level packages. You should install whichever Bioconductor packages you want into the normal library, and then make a copy of that. This copy will be your development library.\ncp -R productionLibrary developmentLibrary\nI also assume that you are using a local (i.e. sits in your home directory) .Renviron file to control where R installs the packages.\nChanging Versions\nRStudio really needs the environment variable RSTUDIO_WHICH_R set to know where R is, and R looks at R_LIBS in the .Renviron file. So I simply create two shell scripts that get sourced.\nuseRDev.sh\n#!/bin/sh\nexport RSTUDIO_WHICH_R=/pathToDevR/bin/R\necho \"R_LIBS=pathtoDevLibs\" > .Renviron\nThen I can simply do source useRDev.sh when I need to use the development R and library. Note that you will need to start RStudio from the shell for it to respect this environment variable. RStudio generally seems to install to /usr/lib/rstudio/bin/rstudio.\nresetR.sh\n#!/bin/sh\nexport RSTUDIO_WHICH_R=/pathtoReleaseR/bin/R\necho \"R_LIBS=pathtoReleaseLibs\" > .Renviron\nThis resets my variables by doint source resetR.sh.\nBioconductor Dev Version\nTo setup Bioconductor to use the develoment version, simply:\nsource useRDev.sh\nrstudio\n\n# once in RStudio\nlibrary(BiocInstaller)\nuseDev()\nbiocLite(ask=F) # this will update all the installed bioconductor packages\nI know this is not the most ideal situation, because I am rewriting over files, but it is working for me, and I thought it might help somone else.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T23:06:32-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-08-16-reproducible-methods/",
    "title": "Reproducible Methods",
    "description": "A short missive on reproducibility, especially within computational work.",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2013-08-16",
    "categories": [
      "open-science",
      "reproducibility"
    ],
    "contents": "\nScience is built on the whole idea of being able to reproduce results, i.e. if I publish something, it should be possible for someone else to reproduce it, using the description of the methods used in the publication. As biological sciences have become increasingly reliant on computational methods, this has become a bigger and bigger issue, especially as the results of experiments become dependent on independently developed computational code, or use rather sophisticated computer packages that have a variety of settings that can affect output, and multiple versions. For further discussion on this issue, you might want to read 1, 2.\nI recently read a couple of different publications that really made me realize how big a problem this is. I want to spend some time showing what the problem is in these publications, and why we should be concerned about the current state of computational analytical reproducibility in life-sciences.\nIn both the articles mentioned below, I do not believe that I, or anyone not associated with the project, would be able to generate even approximately similar results based solely on the raw data and the description of methods provided. Ultimately, this is a failure of both those doing the analysis, and the reviewers who reviewed the work, and is a rather deplorable situation for a field that prides itself verification of results. This is why I’m saying these are bad bioinformatics methods sections.\nPuthanveettil et al., Synaptic Transcriptome\nPuthanveettil et al, 2013 had a paper out earlier titled “A strategy to capture and characterize the synaptic transcriptome” in PNAS. Although the primary development reported is a new method of characterizing RNA complexes that are carried by kinesin, much of the following analysis is bioinformatic in nature.\nFor example, they used BLAST searches to identify the RNA molecules, a cutoff value is reported in the results. However, functional characterization using Gene Ontology (GO) was carried out by “Bioinformatics analyses” (see the top of pg3 in the PDF). No mention of where the GO terms came from, which annotation source was used, or any software mentioned. Not in the results, discussion, or methods, or the supplemental methods. The microarray data analysis isn’t too badly described, but the 454 sequencing data processing isn’t really described at all.\nMy point is, that even given their raw data, I’m not sure I would be able to even approximate their results based on the methods reported in the methods section.\nGulsuner et al., Schizophrenia SNPs\nGulsuner et al published a paper in Cell in August 2013 titled “Spatial and Temporal Mapping of De Novo Mutations in Schizophrenia to a Fetal Prefrontal Cortical Network”. This one also looks really nice, they look for de novo mutations (i.e. new mutations in offspring not present in parents or siblings) that mess up genes that are in a heavily connected network, and also examine gene co-expression over brain development time-scales. Sounds really cool, and the results seem like they are legit, based on my reading of the manuscript. I was really impressed that they even used randomly generated networks to control the false discovery rate!\nHowever, almost all of the analysis again depends on a lot of different bioinformatic software. I do have to give the authors props, they actually give the full version of each tool used. But no mention of tool specific settings (which can generate vastly different results, see Exome Sequencing of the methods).\nThen there is this bombshell: “The predicted functional impact of each candidate de novo missense variant was assessed with in silico tools.” (near top of pg 525 of the PDF). Rrrreeeaaaalllly now. No actual quote of which tools were used, although the subsequent wording and references provided imply that they were PolyPhen2, SIFT, and the Grantham Method. But shouldn’t that have been stated up front? Along with any settings that were changed from default??\nThere is no raw data available, only their reported SNPs. Not even a list of all the SNPs that were potentially considered, so that I could at least go from those and re-run the later analysis. I have to take their word for it (although I am glad at least the SNPs they used in later analyses are reported).\nFinally, the random network generation. I’d like to be able to see that code, go over it, and see what exactly it was doing to verify it was done correctly. It likely was, based on the histograms provided, but still, these are where small errors creep in and result in invalid results.\nAs above, even if the raw data was available (didn’t see an SRA accession or any other download link), I’m not sure I could reproduce or verify the results.\nWhat to do??\nHow do we fix this problem? I think scripts and workflows used to run any type of bioinformatic analyses have to become first class research objects. And we have to teach scientists to write them and use them in a way that makes them first class research objects. So in the same way that a biologist might ask for verification of immunostaining, etc, bioinformaticians should ask that given known input, a script generates reasonable output.\nI know there has been discussion on this before, and disagreement, especially with the exploratory nature of research. However, once you’ve got something working right, you should be able to test it. Reviewers should be asking if it is testable, or the code should be available for others to test.\nI also think we as a community should do more to point out the problem. i.e. when we see it, point it out to others. I’ve done that here, but I don’t know how much should be formal. Maybe we need a new hashtag, #badbioinfomethodsection, and point links to papers that do this. Conversely, we should also point to examples when it is done right (#goodbioinfomethodsection??), and if you are bioinformatician or biologist who does a lot of coding, share your code, and at least supply it as supplemental materials. Oh, and maybe take a SoftwareCarpentry class, and look up git.\nPosted on August 16, 2013 at http://robertmflight.blogspot.com/2013/08/reproducible-methods-or-bad.html, raw markdown at https://github.com/rmflight/blogPosts/blob/master/reproducible_methods.md\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T22:58:46-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-07-11-r-interface-for-teaching/",
    "title": "R Interface for Teaching",
    "description": "What is the best interface for teaching a language like R?",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2013-07-11",
    "categories": [
      "R",
      "teaching",
      "notebooks"
    ],
    "contents": "\nKaitlin Thaney asked on Twitter last week about using Ramnath Vaidyanathan’s new interactive R notebook 1 2 for teaching.\nNow, to be clear up front, I am not trying to be mean to Ramnath, discredit his work, or the effort that went into that project. I think it is really cool, and has some rather interesting potential applications, but I don’t really think it is the right interface for teaching R. I would argue that the best interface for teaching R right now is RStudio. Keep reading to find out why.\niPython Notebook\nFirst, I believe Ramnath when he says he was inspired by the iPython Notebook that makes it so very nice to do interactive, reproducible Python coding. Software Carpentry has been very successfully using them for helping to teach Python to scientists.\nHowever, the iPython Notebook is an interesting beast for this purpose. You are able to mix markdown blocks and code blocks. In addition, it is extremely simple to break up your calculations into units of related code, and re-run those units as needed. This is particularly useful when writing new functions, because you can write the function definition, and a test that displays output in one block, and then the actual computations in subsequent blocks. It makes it very easy to keep re-running the same block of code over and over until it is correct, which allows one to interactively explore changes to functions. This is awesome for learning Python and prototyping functions.\nIn addition to being able to repeatedly write -> run -> modify in a loop, you can also insert prose describing what is going on in the form of markdown. This is a nice lightweight syntax that generates html. So it becomes relatively easy to document the why of something.\nR Notebook\nUnfortunately, the R notebook that Ramnath has put up is not quite the same beast. It is an Ace editor window coupled to an R process that knits the markdown and displays the resultant html. This is really cool, and I think will be useful in many other applications, but not for teaching in an interactive environment.\nRStudio as a Teaching Environment\nLets think. We want something that lets us repeatedly write -> run -> modify on small code blocks in R, but would be great if it was some kind of document that could be shared, and re-run.\nI would argue that the editor environment in RStudio when writing R markdown (Rmd) files is the solution. R code blocks behave much the same as in iPython notebook, in that they are colored differently, set apart, have syntax highlighting, and can be easily repeatedly run using the code chunk menu. Outside of code blocks is assumed to be markdown, making it easy to insert documentation and explanation. The code from the code blocks is sent to an attached R session, where objects can be further investigated if required, and results are displayed.\nThis infrastructure supplies an interactive back and forth between editor and execution environment, with the ability to easily group together units of code.\nIn addition, RStudio has git integration baked in, so it becomes easy to get started with some basic version control.\nFinally, RStudio is cross-platform, has tab completion among other standard IDE goodies, and its free.\nFeedback\nI’ve gotten some feedback on twitter about this, and I want to update this post to address it.\nHard to Install\nOne comment was that installing R, RStudio and necessary packages might be hard. True, it might be. However, I have done multiple installs of R, RStudio, Python, and iPython Notebook in both Linux and Windows, and I would argue that the level of difficulty is at least the same.\nMoving from Presentation to Coding\nI think this is always difficult, especially if you have a powerpoint, and your code is in another application. However, the latest dev version of RStudio (download) now includes the ability to view markdown based presentations in an attached window. This is probably one of the potentially nicest things for doing presentations that actually involve editing actual code.\nEdit: added download links for Rstudio preview\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T22:38:38-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-30-storing-package-data-in-custom-environments/",
    "title": "Storing Package Data in Custom Environments",
    "description": "How do you keep track of stuff for your own package without cluttering the users global space or setting a bunch of options?",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2013-05-30",
    "categories": [
      "R",
      "packages"
    ],
    "contents": "\nIf you do R package development, sometimes you want to be able to store variables specific to your package, without cluttering up the users workspace. One way to do this is by modifying the global options. This is done by packages grDevices and parallel. Sometimes this doesn’t seem to work quite right (see this issue for example.\nAnother way to do this is to create an environment within your package, that only package functions will be able to see, and therefore read from and modify. You get a space to put package specific stuff, the user can’t see it or modify it directly, and you just need to write functions that do the appropriate things to that environment (adding variables, reading them, etc). This sounds great in practice, but I wasn’t clear on how to do this, even after reading the help page on environments, the R documentation, or even Hadley’s excellent writeup. From all these sources, I could glean that one can create environments, name them, modify them, etc, but wasn’t sure how to work with this within a package.\nI checked out the knitcitations package to see how it was done. When I looked, I realized that it was pretty obvious in retrospect. In zzz.R, initialize the environment, assigning it to a variable. When you need to work with the variables inside, this variable will be accessible to your package, and you simply use the get and assign functions like you would if you were doing anything on the command line.\nTo make sure I had it figured out, I created a very tiny package to create a custom environment and functions for modifying it. Please feel free to examine, download, install (using devtools]) and see for yourself.\nI have at least two projects where I know I will use this, and I’m sure others might find it useful as well.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T22:28:25-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-10-writing-up-scientific-results-and-literate-programming/",
    "title": "Writing Up Scientific Results and Literate Programming",
    "description": "My thoughts on using literate programming to investigate and report scientific results",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2013-05-10",
    "categories": [
      "literate-programming"
    ],
    "contents": "\nAs an academic researcher, my primary purpose is to find some new insight, and subsequently communicate this insight to the general public. The process of doing this is traditionally thought to be:\nfrom observations of the world, generate a hypothesis\ndesign experiments to test hypothesis\nanalyse results of the experiments to determine if hypothesis correct\nwrite report to communicate results to others (academics and / or general public)\nAnd then repeat.\nThis is the way people envision it happening. And I would imagine that in some rare cases, this is what actually happens. However, I think many researchers would agree that this is not what normally happens. In the process of doing steps 3 and 4, your hypothesis in 1 will be modified, which modifies the experiments in 2, and so on and so forth. This makes the process of scientific discovery a very iterative process, often times right up to the report writing.\nFor some of this, it takes a long time to figure this out. I’ll never forget a professor during my PhD who suggested that you write the paper, and then figure out what experiments you should do to generate the results that would support or disprove the hypothesis you made in the paper. At the time I thought he was nuts, but when you start writing stuff, and looking at how all the steps of experiment and reporting can become intertwined, it doesn’t seem like a bad idea. note1\nLiterate programming\nWhat does this have to do with literate programming? For those who don’t know, literate programming is a way to mix code and prose together in one document (in R we use knitr & sweave, python now has the iPython notebook as an option). This literate programming paradigm (combined with markdown as the markup language instead of latex thanks to knitr) is changing how I actually write my papers and do research in general.\nHow that changes writing\nAs I’ve previously described 12, RStudio makes the use of knitr and generation of literate documents using computations in R incredibly easy. Because my writing environment and programming environment are tightly coupled together, I can easily start writing what looks like a shareable, readable publication as soon as I start writing code. Couple this together with a CVS like git, and you have a way to follow the complete providence of a publication from start to finish.\nInstead of commenting my code to explain why I am doing something, I explain what I am doing in the prose, and then write the code to carry out that analysis. This changes my writing and coding style, and makes the interplay among the steps of writing scientific reports above much more explicit. I think it is a good thing, and will hopefully make my writing and research more productive.\nNotes\n1. I am not suggesting that one only do experiments that will support the experiment, but writing out the paper at least gives you a framework for doing the experiments, and doing initial analysis. One should always be willing to modify the publication / hypothesis based on what the experiments tell you.\nSources\nPublished 10.05.13 here\nThe source markdown for this document is available here\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T22:24:43-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-10-09-writing-papers-using-r-markdown/",
    "title": "Writing Papers Using R Markdown",
    "description": "How I used RMarkdown to write a manuscript",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2012-10-09",
    "categories": [
      "R",
      "open-science",
      "reproducibility"
    ],
    "contents": "\nI have been watching the activity in RStudio and knitr for a while, and have even been using Rmd (R markdown) files in my own work as a way to easily provide commentary on an actual dataset analysis. Yihui has proposed writing papers in markdown and posting them to a blog as a way to host a statistics journal, and lots of people are now using knitr as a way to create reproducible blog posts that include code (including yours truly).\nThe idea of writing a paper that actually includes the necessary code to perform the analysis, and is actually readable in its raw form, and that someone else could actually run was pretty appealing. Unfortunately, I had not had the time or opportunity to actually try it, until recently our group submitted a conference paper that included a lot of analysis in R that seemed like the perfect opportunity to try this. (I will link to the paper here when I hear more, or get clearance from my PI). Originally we wrote the paper in Microsoft(r) Word, but after submission I decided to see what it would have taken to write it as an Rmd document that could then generate markdown or html.\nIt turned out that it was not that hard, but it did force me to do some things differently. This is what I want to discuss here.\nAdvantages\nI actually found it much easier to have the text with the analysis (in contrast to having to be separate in a Word document), and upon doing the conversion, discovered some possible numerical errors that crept in because of having to copy numerical results separately (that is the nice thing about being able to insert variable directly into the text). In addition, the Word template for the submission didn’t play nice with automatic table and figure numbering, so our table and figure numbering got messed up in the submission. So overall, I’d say it worked out better with the Rmd file overall, even with the having to create functions to handle table and figure numbering properly myself (see below).\nTables and Figures\nAs I’m sure most of you know, Word (and other WYSIWYG editors) have ability to keep track of your object numbers, this is especially nice for keeping your figure and table numbers straight. Of course, there is no such ability built into a static text file, but I found it was easy to write a couple of functions for this. The way I came up with is to have a variable that contains a label for the figure or table, a function that increments the counter when new figures or tables are added, and a function that prints the associated number for a particular label. This does require a bit of forethought on the part of the writer, because you may have to add a table or figure label to the variable long before you actually create it, but as long as you use sane (i.e. descriptive) labels, it shouldn’t be a big deal. Let me show you what I mean.\nCounting\n\n\nincCount <- function(inObj, useName){\n  nObj <- length(inObj)\n  useNum <- max(inObj) + 1\n  inObj <- c(inObj, useNum)\n  names(inObj)[nObj+1] <- useName\n  inObj\n}\nfigCount <- c(\"_\"=0)\ntableCount <- c(\"_\"=0)\n\n\n\nThe incCount function is very simple, it takes an object, checks the maximum count, and then adds an incremental value with the supplied name. In this example, I initialized the figCount and tableCount objects with a non-sensical named value of zero.\nNow in the process of writing, I decide I’m going to need a table on the amount of time spent by post-docs writing blog posts in different years of their post-doc training. Lets call this t.blogPostDocs. Notice that this is a fairly descriptive name. We can assign it a number like so:\n\n\ntableCount <- incCount(tableCount, \"t.blogPostDocs\")\ntableCount\n\n\n             _ t.blogPostDocs \n             0              1 \n\nInserting\nSo now we have a variable with a named number we can refer to. But how do we insert it into the text? We are going to use another function that will let us insert either the text with a link, or just the text itself.\n\n\npasteLabel <- function(preText, inObj, objName, insLink=TRUE){\n  objNum <- inObj[objName]\n  \n  useText <- paste(preText, objNum, sep=\" \")\n  if (insLink){\n    useText <- paste(\"[\", useText, \"](#\", objName, \")\", sep=\"\")\n  }\n  useText\n}\n\n\n\nThis function allows us to insert the table number like so:\n\nr I(pasteLabel(\"Table\", tableCount, \"t.blogPostDocs\"))\n\nThis would be inserted into a normal inline code block. The I makes sure that the text will appear as normal text, and not get formatted as a code block. The default behavior is to insert as a relative link, thereby enabling the use of relative links to link where a table / figure is mentioned to its actual location. For example, we can insert the anchor link like so:\n<a id=\"t.blogPostDocs\"><\/a>\nMarkdown Tables\nFollowed by the actual table text. This brings up the subject of markdown tables. I also wrote a function (thanks to Yihui again) that transforms a normal R data.frame to a markdown table.\n\n\ntableCat <- function(inFrame){\n  outText <- paste(names(inFrame), collapse=\" | \")\n  outText <- c(outText, paste(rep(\"---\", ncol(inFrame)), collapse=\" | \"))\n  invisible(apply(inFrame, 1, function(inRow){\n    outText <<- c(outText, paste(inRow, collapse=\" | \"))\n  }))\n  return(outText)\n}\n\n\n\nLets see it in action.\n\n\npostDocBlogs <- data.frame(PD=c(\"p1\", \"p2\", \"p3\"), NBlog=c(4, 10, 2), Year=c(1, 4, 2))\npostDocBlogs\n\n\n  PD NBlog Year\n1 p1     4    1\n2 p2    10    4\n3 p3     2    2\n\npostDocInsert <- tableCat(postDocBlogs)\npostDocInsert\n\n\n[1] \"PD | NBlog | Year\" \"--- | --- | ---\"   \"p1 |  4 | 1\"      \n[4] \"p2 | 10 | 4\"       \"p3 |  2 | 2\"      \n\nTo actually insert it into the text, use a code chunk with results='asis' and echo=FALSE.\n\n\ncat(postDocInsert, sep=\"\\n\")\n\n\nPD\nNBlog\nYear\np1\n4\n1\np2\n10\n4\np3\n2\n2\n\nBefore inserting the table though, you might want an inline code with the table number and caption, like this:\nI(pasteLabel(\"Table\", tableCount, \"t.blogPostDocs\", FALSE)) This is the number of blog posts and year of training for post-docs.\nTable 1 This is the number of blog posts and year of training for post-docs.\nRemember for captions to set the insLink variable to FALSE so that you don’t generate a link from the caption.\nFigures\nOftentimes, you will have code that generates the figure, and then you want to insert the figure at a different point. This is accomplished by the judicious use of echo and include chunk options.\nFor example, we can create a ggplot2 figure and store it in a variable in one chunk, and then print it in a later chunk to actually insert it into the text body.\n\n\nplotData <- data.frame(x=rnorm(1000, 1, 5), y=rnorm(1000, 0, 2))\nplotKeep <- ggplot(plotData, aes(x=x, y=y)) + geom_point()\nfigCounts <- incCount(figCount, \"f.randomFigure\")\n\n\n\nAnd now we decide to actually insert it using print(plotKeep) with the option of echo=FALSE:\n\n\n\nFigure 1. A random figure.\nNumerical result formatting\nWhen R prints a number, it normally likes to do so with lots of digits. This is not probably what you want either in a table or when reporting a number in a sentence. You can control that by using the format function. When generating a new variable, the number of digits to display when printing will be saved, and when used on a variable directly, only the defined number of digits will display.\nEcho and Include\nThis brings up the issue of how to keep the code from appearing in the text body. I found depending on the particulars, either using echo=FALSE or include=FALSE would do the job. This is meant to be a paper, a reproducible one, but a paper nonetheless, and therefore the code should not end up in the text body.\nReferences\nOne thing I haven’t done yet is convert all the references. I am planning to try using the knitcitations package. I will probably post on that experience.\nHTML generation\nBecause I use RStudio, I set up a modified function For generating a full html version of the paper, changing the default RStudio markdown render options like so:\nhtmlOptions <- markdownHTMLOptions(defaults=TRUE)\nhtmlOptions <- htmlOptions[htmlOptions != \"hard_wrap\"]\nmarkdownToHTML(inputFile, outputFile, options = htmlOptions)\nThis should be added to a .Rprofile file either in your home directory or in the directory you start R in (this is especially useful for modification on a per project basis).\nI do this because when I write my documents, I want the source to be readable online. If this is a github hosted repo, that means being displayed in the github file browser, which does not do line wrapping. So I set up a 120 character line in my editor, and try very hard to stick to that.\nFunction source\nYou can find the previously mentioned functions in a github gist here.\nPost source\nThe source files for this blog post can be found at: Rmd, md, and html.\nPosted on October 9, 2012, at http://robertmflight.blogspot.com/2012/10/writing-papers-using-r-markdown.html\nEdit: added section on formatting numerical results\nEdit: added session info\n\nR version 4.0.0 (2020-04-24)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Pop!_OS 20.04 LTS\n\nMatrix products: default\nBLAS:   /software/R-4.0.0/lib/R/lib/libRblas.so\nLAPACK: /software/R-4.0.0/lib/R/lib/libRlapack.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] ggplot2_3.3.3\n\nloaded via a namespace (and not attached):\n [1] pillar_1.4.7      compiler_4.0.0    highr_0.8        \n [4] tools_4.0.0       digest_0.6.27     downlit_0.2.1    \n [7] evaluate_0.14     lifecycle_1.0.0   tibble_3.0.6     \n[10] gtable_0.3.0      pkgconfig_2.0.3   rlang_0.4.10     \n[13] DBI_1.1.1         distill_1.2       yaml_2.2.1       \n[16] xfun_0.21         withr_2.4.1       stringr_1.4.0    \n[19] dplyr_1.0.4       knitr_1.31        generics_0.1.0   \n[22] vctrs_0.3.6       grid_4.0.0        tidyselect_1.1.0 \n[25] glue_1.4.2        R6_2.5.0          fansi_0.4.2      \n[28] rmarkdown_2.6     purrr_0.3.4       farver_2.0.3     \n[31] magrittr_2.0.1    scales_1.1.1      ellipsis_0.3.1   \n[34] htmltools_0.5.1.1 assertthat_0.2.1  colorspace_2.0-0 \n[37] labeling_0.4.2    stringi_1.5.3     munsell_0.5.0    \n[40] crayon_1.4.1     \n\n\n\n\n",
    "preview": "posts/2012-10-09-writing-papers-using-r-markdown/writing-papers-using-rmarkdown_files/figure-html5/figureInsert-1.png",
    "last_modified": "2021-02-18T22:17:37-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2012-08-15-journal-club-2012-08-15/",
    "title": "Journal Club 2012-08-15",
    "description": "A summary of the paper Google Goes Cancer as was discussed in our journal club.",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2012-08-15",
    "categories": [
      "journal-club"
    ],
    "contents": "\nI just came back from our Bioinformatic group (a rather loose association of various researchers at UofL interested in and doing bioinformatics) journal club, where we discussed this recent paper:\nGoogle Goes Cancer: Improving Outcome Prediction for Cancer Patients by Network-Based Ranking of Marker Genes\nBesides the catchy title that makes one believe that perhaps Google is getting into cancer research (maybe they are and we don’t know it yet), there were some interesting aspects to this paper.\nPremise\nThe premise is that they can combine gene expression data and network data to find better associations between gene expression data and a particular disease endpoint. The way this is carried out is through the use of the TRANSFAC transcription factor - gene target database for the network, the correlation of the gene expression with the disease status as the importance of a gene with the disease, and the Google PageRank as the means to transfer the network knowledge to the gene expression data. They call their method NetRank.\nNote that the general idea had already been tried in this paper on GeneRank.\nImplementation\nRank the genes with disease status (poor or good prognosis) using a method (SAM, t-test, fold-change, correlation, NetRank). Pick n top genes, and develop a predictive model using a support vector machine. Wash, rinse, repeat several times to find the best set, varying the number of top genes, and the number of samples used in the training set.\nFor NetRank, the top genes were decided by using a sub-optimization based on varying d, the dampening factor in the PageRank algorithm that determines how much information can be transferred to other genes. The best value of d determined in this study was 0.3.\nAll other methods used just the 8000 genes that passed filtering, but NetRank used all the genes on the array, with those that were filtered out had their initial correlations set to 0, so that they were still in the network representation.\nMonte Carlo cross-validationDid it work?\nFrom the paper, it appears to have worked. Using a monte-carlo cross-validation, they were able to achieve over 70% prediction rates. And this was better than any of the other methods they used to associate genes with the disease, including SAM, t-test, fold-change, and raw correlations.\nNetRank feature selection performanceIssues\nAs we discussed the article, some questions did come up.\nWhat was the variation in d depending on the size of the training set?\nHow consistent were the genes that came out as biomarkers?\nIt would be nice to try this methodology on a series of independent, but related cancer datasets (ie breast or lung cancer) and see how consistent the lists are. This was done here.\nWhat happens if the genes that don’t pass filtering are removed from the network entirely?\nWere the problems reported with not-filtering genes due to having only two disease points (poor and good prognosis) to calculate a correlation of expression with?\nHow many iterations does it take to achieve convergence?\nThe list of genes they come up with are fairly well known cancer genes. We were kindof surprised that they didn’t seem to come up novel genes associated directly with pancreatic cancer.\nWhy is d so variable depending on the cancer examined?\nThings to try\nCould we improve on this by instead of taking just the top-ranked genes, look for the top ranked cliques, i.e. take the top gene, remove anything in its immediate neighborhood, and then go to the next one?\nWhat would happen if we used a directed network based on connected Reactome or KEGG pathways?\nFind this post online at: http://robertmflight.blogspot.com/2012/08/journal-club-150812.html\nAuthored using Markdown, and the R Markdown package. Published on 15.08.12\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T22:12:27-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-07-13-creating-custom-cdf-s-for-affymetrix-chips-in-bioconductor/",
    "title": "Creating Custom CDF's for Affymetrix Chips in Bioconductor",
    "description": "Examples of messing with Affymetrix CDF data in bioconductor.",
    "author": [
      {
        "name": "Robert M Flight",
        "url": {}
      }
    ],
    "date": "2012-07-13",
    "categories": [
      "R",
      "bioconductor",
      "cdf"
    ],
    "contents": "\n\n\n\nWhat?\nFor those who don’t know, CDF files are chip definition format files that define which probes belong to which probesets, and are necessary to use any of the standard summarization methods such as RMA, and others.\nWhy?\nBecause we can, and because custom definitions have been shown to be quite useful. See the information over at Brainarray.\nWhy not somewhere else?\nA lot of times other people create custom CDF files based on their own criteria, and make it subsequently available for others to use (see the Brainarray for an example of what some are doing, as well as PlandbAffy)\nYou have a really nifty idea for a way to reorganize the probesets on an Affymetrix chip to perform a custom analysis, but you don’t want to go to the trouble of actually creating the CDF files and Bioconductor packages normally required to do the analysis, and yet you want to test and develop your analysis method.\nHow?\nIt turns out you are in luck. At least for AffyBatch objects in Bioconductor (created by calling ReadAffy), the CDF information is stored as an attached environment that can be easily hacked and modified to your hearts content. Environments in R are quite important and useful, and I wouldn’t have come up with this if I hadn’t been working in R for the past couple of years, but figured someone else might benefit from this knowledge.\nThe environment\nIn R, one can access an environment like so:\n\n\nget(\"objName\", envName) # get the value of object in the environment\nls(envName)\n\n\n\nWhat is also very cool, is that one can extract the objects in an environment to a list, and also create their own environment from a list using list2env. Using this methodology, we can create our own definition of probesets that can be used by standard Bioconductor routines to summarize the probes into probesets.\nA couple of disclaimers:\nI have only tried this on 3’ expression arrays\nThere might be a better way to do this, but I couldn’t find it (let me know in the comments)\nExample\n\n\nrequire(affy)\nrequire(estrogen)\nrequire(hgu95av2cdf)\n\ndatadir = system.file(\"extdata\", package=\"estrogen\")\n\npd = read.AnnotatedDataFrame(file.path(datadir, \"estrogen.txt\"), header=TRUE, sep=\"\", row.names=1)\npData(pd)\n\n\n             estrogen time.h\nlow10-1.cel    absent     10\nlow10-2.cel    absent     10\nhigh10-1.cel  present     10\nhigh10-2.cel  present     10\nlow48-1.cel    absent     48\nlow48-2.cel    absent     48\nhigh48-1.cel  present     48\nhigh48-2.cel  present     48\n\ncelDat = ReadAffy(filenames = rownames(pData(pd)), \n                  phenoData = pd,\n                  verbose=TRUE, celfile.path=datadir)\n\n\n1 reading /software/R_libs/R400/estrogen/extdata/low10-1.cel ...instantiating an AffyBatch (intensity a 409600x8 matrix)...done.\nReading in : /software/R_libs/R400/estrogen/extdata/low10-1.cel\nReading in : /software/R_libs/R400/estrogen/extdata/low10-2.cel\nReading in : /software/R_libs/R400/estrogen/extdata/high10-1.cel\nReading in : /software/R_libs/R400/estrogen/extdata/high10-2.cel\nReading in : /software/R_libs/R400/estrogen/extdata/low48-1.cel\nReading in : /software/R_libs/R400/estrogen/extdata/low48-2.cel\nReading in : /software/R_libs/R400/estrogen/extdata/high48-1.cel\nReading in : /software/R_libs/R400/estrogen/extdata/high48-2.cel\n\nThis loads up the data, reads in the raw data, and gets it ready for us to use. Now, lets see what is in the actual CDF environment.\n\n\ntopProbes <- head(ls(hgu95av2cdf)) # get a list of probesets\ntopProbes\n\n\n[1] \"100_g_at\"  \"1000_at\"   \"1001_at\"   \"1002_f_at\" \"1003_s_at\"\n[6] \"1004_at\"  \n\nexSet <- get(topProbes[1], hgu95av2cdf)\nexSet\n\n\n          pm     mm\n [1,] 175218 175858\n [2,] 356689 357329\n [3,] 227696 228336\n [4,] 237919 238559\n [5,] 275173 275813\n [6,] 203444 204084\n [7,] 357984 358624\n [8,] 368524 369164\n [9,] 285352 285992\n[10,] 304510 305150\n[11,] 159937 160577\n[12,] 223929 224569\n[13,] 282764 283404\n[14,] 270003 270643\n[15,] 303343 303983\n[16,] 389048 389688\n\nWe can see here that the first probe set 100_g_at has 16 perfect-match and mis-match probes in associated with it.\nLets summarize the original data using RMA.\n\n\nrma1 <- exprs(rma(celDat))\n\n\nBackground correcting\nNormalizing\nCalculating Expression\n\nhead(rma1)\n\n\n          low10-1.cel low10-2.cel high10-1.cel high10-2.cel\n100_g_at     9.642896    9.741496     9.537036     9.353625\n1000_at     10.398169   10.254362    10.003971     9.903528\n1001_at      5.717613    5.881008     5.859563     5.954028\n1002_f_at    5.512596    5.801807     5.571065     5.608132\n1003_s_at    7.783927    8.007975     8.037999     7.835120\n1004_at      7.289162    7.603670     7.488539     7.771506\n          low48-1.cel low48-2.cel high48-1.cel high48-2.cel\n100_g_at     9.591697    9.570590     9.475796     9.530655\n1000_at     10.374866   10.033520    10.345066     9.863321\n1001_at      5.960540    6.020889     5.981080     6.285192\n1002_f_at    5.390064    5.494511     5.508104     5.630107\n1003_s_at    7.926487    8.138870     7.994937     8.233338\n1004_at      7.521789    7.599544     7.456149     7.675171\n\nNow lets get the data as a list, and then create a new environment to be used for summarization.\n\n\nallSets <- ls(hgu95av2cdf)\nallSetDat <- mget(allSets, hgu95av2cdf)\n\nallSetDat[1]\n\n\n$`100_g_at`\n          pm     mm\n [1,] 175218 175858\n [2,] 356689 357329\n [3,] 227696 228336\n [4,] 237919 238559\n [5,] 275173 275813\n [6,] 203444 204084\n [7,] 357984 358624\n [8,] 368524 369164\n [9,] 285352 285992\n[10,] 304510 305150\n[11,] 159937 160577\n[12,] 223929 224569\n[13,] 282764 283404\n[14,] 270003 270643\n[15,] 303343 303983\n[16,] 389048 389688\n\nhgu2 <- list2env(allSetDat)\ncelDat@cdfName <- \"hgu2\"\n\nrma2 <- exprs(rma(celDat))\n\n\nBackground correcting\nNormalizing\nCalculating Expression\n\nhead(rma2)\n\n\n          low10-1.cel low10-2.cel high10-1.cel high10-2.cel\n100_g_at     9.642896    9.741496     9.537036     9.353625\n1000_at     10.398169   10.254362    10.003971     9.903528\n1001_at      5.717613    5.881008     5.859563     5.954028\n1002_f_at    5.512596    5.801807     5.571065     5.608132\n1003_s_at    7.783927    8.007975     8.037999     7.835120\n1004_at      7.289162    7.603670     7.488539     7.771506\n          low48-1.cel low48-2.cel high48-1.cel high48-2.cel\n100_g_at     9.591697    9.570590     9.475796     9.530655\n1000_at     10.374866   10.033520    10.345066     9.863321\n1001_at      5.960540    6.020889     5.981080     6.285192\n1002_f_at    5.390064    5.494511     5.508104     5.630107\n1003_s_at    7.926487    8.138870     7.994937     8.233338\n1004_at      7.521789    7.599544     7.456149     7.675171\n\nWhat about removing the MM columns? RMA only uses the PM, so it should still work.\n\n\nallSetDat <- lapply(allSetDat, function(x){\n  x[,1, drop=F]\n})\n\nallSetDat[1]\n\n\n$`100_g_at`\n          pm\n [1,] 175218\n [2,] 356689\n [3,] 227696\n [4,] 237919\n [5,] 275173\n [6,] 203444\n [7,] 357984\n [8,] 368524\n [9,] 285352\n[10,] 304510\n[11,] 159937\n[12,] 223929\n[13,] 282764\n[14,] 270003\n[15,] 303343\n[16,] 389048\n\nhgu3 <- list2env(allSetDat)\ncelDat@cdfName <- \"hgu3\"\nrma3 <-exprs(rma(celDat))\n\n\nBackground correcting\nNormalizing\nCalculating Expression\n\nhead(rma3)\n\n\n          low10-1.cel low10-2.cel high10-1.cel high10-2.cel\n100_g_at     9.642896    9.741496     9.537036     9.353625\n1000_at     10.398169   10.254362    10.003971     9.903528\n1001_at      5.717613    5.881008     5.859563     5.954028\n1002_f_at    5.512596    5.801807     5.571065     5.608132\n1003_s_at    7.783927    8.007975     8.037999     7.835120\n1004_at      7.289162    7.603670     7.488539     7.771506\n          low48-1.cel low48-2.cel high48-1.cel high48-2.cel\n100_g_at     9.591697    9.570590     9.475796     9.530655\n1000_at     10.374866   10.033520    10.345066     9.863321\n1001_at      5.960540    6.020889     5.981080     6.285192\n1002_f_at    5.390064    5.494511     5.508104     5.630107\n1003_s_at    7.926487    8.138870     7.994937     8.233338\n1004_at      7.521789    7.599544     7.456149     7.675171\n\nWhat if we only want to use the first 5 probesets?\n\n\nallSetDat <- allSetDat[1:5]\nhgu4 <- list2env(allSetDat)\ncelDat@cdfName <- \"hgu4\"\ncelDat\n\n\nAffyBatch object\nsize of arrays=640x640 features (21 kb)\ncdf=hgu4 (5 affyids)\nnumber of samples=8\nnumber of genes=5\nannotation=hgu95av2\nnotes=\n\nrma4 <- exprs(rma(celDat))\n\n\nBackground correcting\nNormalizing\nCalculating Expression\n\nrma4\n\n\n          low10-1.cel low10-2.cel high10-1.cel high10-2.cel\n100_g_at     9.463007    9.554665     9.449050     9.401976\n1000_at     10.182753   10.009785    10.009785     9.970396\n1001_at      5.943840    6.005177     5.944015     6.089531\n1002_f_at    5.787166    5.846225     5.816964     5.814798\n1003_s_at    7.750877    7.769401     7.913021     7.864052\n          low48-1.cel low48-2.cel high48-1.cel high48-2.cel\n100_g_at     9.447562    9.457986     9.401366     9.431078\n1000_at     10.102424   10.009785    10.197065     9.889555\n1001_at      6.237329    6.147957     6.189200     6.206669\n1002_f_at    5.763175    5.763175     5.740757     5.755085\n1003_s_at    7.860778    7.917565     7.862614     7.928691\n\ndim(rma4)\n\n\n[1] 5 8\n\nCustom CDF\nTo generate our custom CDF, we are going to set our own names, and take random probes from all of the probes on the chip. The actual criteria of which probes should be together can be made using any method the author chooses.\n\n\nmaxIndx <- 640*640\n\ncustomCDF <- lapply(seq(1,100), function(x){\n  tmp <- matrix(sample(maxIndx, 20), nrow=20, ncol=1)\n  colnames(tmp) <- \"pm\"\n  return(tmp)\n})\n\nnames(customCDF) <- seq(1, 100)\n\nhgu5 <- list2env(customCDF)\ncelDat@cdfName <- \"hgu5\"\nrma5 <- exprs(rma(celDat))\n\n\nBackground correcting\nNormalizing\nCalculating Expression\n\nhead(rma5)\n\n\n    low10-1.cel low10-2.cel high10-1.cel high10-2.cel low48-1.cel\n1      6.448811    6.355482     6.384368     6.623365    6.542498\n10     5.614163    5.819939     5.780212     5.715234    5.782956\n100    8.246599    8.070474     8.055916     7.976191    8.245863\n11     7.474336    7.400735     7.324578     7.494268    7.049670\n12     7.655839    7.403748     7.365558     7.458432    7.586309\n13     7.411904    7.480508     7.441295     7.523525    7.422301\n    low48-2.cel high48-1.cel high48-2.cel\n1      6.602944     6.560628     6.455634\n10     5.759557     5.844312     5.793084\n100    7.938031     8.309788     8.202651\n11     7.185326     7.098154     7.287665\n12     7.373963     7.582550     7.241672\n13     7.227796     7.116470     7.133553\n\nI hope this information is useful to someone else. I know it made my life a lot easier.\n\n\nsessionInfo()\n\n\nR version 4.0.0 (2020-04-24)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Pop!_OS 20.04 LTS\n\nMatrix products: default\nBLAS:   /software/R-4.0.0/lib/R/lib/libRblas.so\nLAPACK: /software/R-4.0.0/lib/R/lib/libRlapack.so\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] parallel  stats     graphics  grDevices utils     datasets \n[7] methods   base     \n\nother attached packages:\n[1] hgu95av2cdf_2.18.0  estrogen_1.34.0     affy_1.66.0        \n[4] Biobase_2.48.0      BiocGenerics_0.34.0\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.6            compiler_4.0.0        BiocManager_1.30.10  \n [4] tools_4.0.0           zlibbioc_1.34.0       digest_0.6.27        \n [7] downlit_0.2.1         bit_4.0.4             RSQLite_2.2.3        \n[10] evaluate_0.14         memoise_2.0.0         preprocessCore_1.50.0\n[13] rlang_0.4.10          DBI_1.1.1             distill_1.2          \n[16] yaml_2.2.1            xfun_0.21             fastmap_1.1.0        \n[19] stringr_1.4.0         knitr_1.31            IRanges_2.22.2       \n[22] vctrs_0.3.6           S4Vectors_0.26.1      stats4_4.0.0         \n[25] bit64_4.0.5           fansi_0.4.2           AnnotationDbi_1.50.3 \n[28] rmarkdown_2.6         blob_1.2.1            magrittr_2.0.1       \n[31] htmltools_0.5.1.1     stringi_1.5.3         cachem_1.0.4         \n[34] affyio_1.58.0        \n\nOriginally published 2013/07/13, moved to http://rmflight.github.io on 2013/12/04.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-18T22:10:45-05:00",
    "input_file": {}
  }
]
